# Story 4.5: QA Report Module

## Status
Ready for Review

## Story
**As a** FancyRAG pipeline maintainer,
**I want** the ingestion QA reporting logic extracted into a dedicated module that renders JSON and Markdown artifacts,
**so that** the refactored pipeline keeps reusable, versioned QA outputs aligned with the guardrails.

## Acceptance Criteria
1. Implement `src/fancyrag/qa/report.py` to house the JSON and Markdown renderers currently in the evaluator, preserving sanitized payloads, version metadata, and directory handling so the module meets the refactor module guardrails. [Source: docs/prd/projects/fancyrag-kg-build-refactor/prd.md#epic-1-kg_buildpy-monolith-decomposition] [Source: docs/architecture/projects/fancyrag-kg-build-refactor.md#3-module-level-design] [Source: src/fancyrag/qa/evaluator.py]
2. Update `IngestionQaEvaluator` to delegate report generation to the new module while keeping the `QaResult` contract (status, summary, versioned paths, anomalies) and threshold enforcement untouched. [Source: docs/architecture/projects/fancyrag-kg-build-refactor.md#3-module-level-design] [Source: src/fancyrag/qa/evaluator.py] [Source: docs/architecture/overview.md#Built-In Tool Playbook]
3. Ensure `fancyrag.kg.pipeline` and CLI wiring continue to write reports under the configured `qa_report_dir` with version `ingestion-qa-report/v1`, sanitized contents, and unchanged failure semantics when QA gating fails. [Source: src/fancyrag/kg/pipeline.py] [Source: docs/architecture/projects/fancyrag-kg-build-refactor.md#4-data-flow] [Source: docs/architecture/source-tree.md#Upcoming Module Layout]
4. Add targeted tests for the new report module (JSON payload, Markdown rendering, scrubbed output) and refresh evaluator/pipeline tests to confirm integration paths per the testing strategy and coding standards. [Source: docs/architecture/projects/fancyrag-kg-build-refactor.md#5-Testing Strategy] [Source: docs/architecture/coding-standards.md#Testing Expectations]
5. Update architecture shards (source tree, module-level design) and Epic 4 documentation to mark the QA report module delivered and keep import direction guidance current. [Source: docs/architecture/source-tree.md#Upcoming Module Layout] [Source: docs/architecture/projects/fancyrag-kg-build-refactor.md#3-module-level-design] [Source: docs/bmad/focused-epics/kg-build-refactor/epic.md#Stories]

## Tasks / Subtasks
- [x] Extract the ingestion QA report rendering logic from `fancyrag.qa.evaluator` into `src/fancyrag/qa/report.py`, exposing helpers that accept sanitized payloads and target directories. (AC: 1) [Source: src/fancyrag/qa/evaluator.py] [Source: docs/architecture/projects/fancyrag-kg-build-refactor.md#3-module-level-design]
- [x] Refactor `IngestionQaEvaluator` to build payloads and invoke the report helpers while maintaining the `QaResult` shape and timing metrics. (AC: 1,2) [Source: src/fancyrag/qa/evaluator.py] [Source: docs/architecture/overview.md#Built-In Tool Playbook]
- [x] Adjust `fancyrag.kg.pipeline` (and any CLI glue) to consume the new report module without changing CLI flags, report paths, or rollback semantics. (AC: 2,3) [Source: src/fancyrag/kg/pipeline.py] [Source: docs/architecture/projects/fancyrag-kg-build-refactor.md#4-data-flow]
- [x] Add pytest coverage for report rendering (JSON + Markdown) and update evaluator/pipeline suites to verify gating still emits versioned artifacts and sanitized payloads. (AC: 4) [Source: docs/architecture/coding-standards.md#Testing Expectations] [Source: docs/architecture/projects/fancyrag-kg-build-refactor.md#5-Testing Strategy]
- [x] Refresh `docs/architecture/source-tree.md`, `docs/architecture/projects/fancyrag-kg-build-refactor.md`, and Epic 4 notes so documentation reflects the delivered module and passes the docs lint guard. (AC: 5) [Source: docs/architecture/source-tree.md#Upcoming Module Layout] [Source: docs/bmad/focused-epics/kg-build-refactor/epic.md#Stories]

## Dev Notes
### Previous Story Insights
- Story 4.4 isolated QA evaluation into `fancyrag.qa.evaluator`; the new report module must stay within the `fancyrag.qa` package and keep the CLI → pipeline → QA import direction intact. [Source: docs/stories/4.4.qa-evaluator.md#Dev Notes] [Source: docs/architecture/projects/fancyrag-kg-build-refactor.md#2-high-level-design]
- Evaluator currently writes reports using `ensure_directory` and `scrub_object`; replicating that behaviour through a dedicated module avoids drift when more QA outputs land. [Source: src/fancyrag/qa/evaluator.py]

### Data Models
- QA summaries aggregate Document and Chunk node metrics plus semantic counts emitted by the pipeline; the report helpers must continue to mirror these structures. [Source: docs/architecture/projects/fancyrag-kg-build-refactor.md#4-data-flow]

### API Specifications
- The CLI exposes `--qa-report-dir` alongside QA threshold flags; the report module must respect these options, keep artifacts versioned as `ingestion-qa-report/v1`, and continue sanitizing payloads through `cli.sanitizer.scrub_object`. [Source: src/fancyrag/kg/pipeline.py] [Source: docs/architecture/overview.md#Built-In Tool Playbook] [Source: src/fancyrag/qa/evaluator.py]

### Component Specifications
- `src/fancyrag/qa/report.py` should provide single-responsibility helpers consumed by the evaluator, aligning with the module layout for the QA package. [Source: docs/architecture/projects/fancyrag-kg-build-refactor.md#3-module-level-design]

### File Locations
- Implementation lives in `src/fancyrag/qa/report.py`, tests under `tests/unit/fancyrag/qa/`, and generated artifacts remain beneath the configured `qa_report_dir`. [Source: docs/architecture/source-tree.md#Upcoming Module Layout] [Source: src/fancyrag/qa/evaluator.py]

### Testing Requirements
- Follow the refactor’s testing strategy: add unit tests for report helpers and keep pipeline/evaluator suites plus integration smoke aligned with pytest layout. [Source: docs/architecture/projects/fancyrag-kg-build-refactor.md#5-Testing Strategy] [Source: docs/architecture/coding-standards.md#Testing Expectations]

### Technical Constraints
- Maintain Python 3.12 compatibility with the pinned Neo4j, Qdrant, and OpenAI dependencies; continue using structured logging and retry guardrails. [Source: docs/architecture/tech-stack.md#Technology Stack] [Source: docs/architecture/coding-standards.md#Core Standards]

### Project Structure Notes
- Updating the report module from “pending” to “delivered” keeps the source tree blueprint synchronized with the live package layout. [Source: docs/architecture/source-tree.md#Upcoming Module Layout]

## Testing
- `PYTHONPATH=src pytest tests/unit/fancyrag/qa/test_report.py`
- `PYTHONPATH=src pytest tests/unit/fancyrag/qa/test_evaluator.py`
- `PYTHONPATH=src pytest tests/unit/fancyrag/kg/test_pipeline.py`
- `PYTHONPATH=src pytest tests/integration/local_stack/test_minimal_path_smoke.py -rs`

## Change Log

| Date       | Version | Description                               | Author |
|------------|---------|-------------------------------------------|--------|
| 2025-10-04 | 0.1     | Draft story capturing QA report extraction | Bob    |
| 2025-10-04 | 1.0     | Implementation ready for review             | Codex  |

## Dev Agent Record
### Agent Model Used
- GPT-5 Codex (2025-10-04)

### Debug Log References
- No new debug log entries; run completed without manual tracing.

### Completion Notes List
- Extracted ingestion QA report generation into `fancyrag.qa.report` and delegated evaluator writes to the module.
- Added dedicated unit coverage plus reran evaluator and pipeline suites; integration smoke passed with Docker stack.
- Refreshed architecture source tree and module design docs to mark the report module delivered.

### File List
- src/fancyrag/qa/report.py
- src/fancyrag/qa/evaluator.py
- src/fancyrag/qa/__init__.py
- tests/unit/fancyrag/qa/test_report.py
- docs/architecture/source-tree.md
- docs/architecture/projects/fancyrag-kg-build-refactor.md
- docs/bmad/focused-epics/kg-build-refactor/epic.md

## QA Results
- Pending

### Review Date: TBD

### Reviewed By: TBD

### Code Quality Assessment
- Pending

### Requirements Traceability
- Pending

### Testing
- Pending

### Risks & Recommendations
- Pending

### Status Recommendation
- Pending
